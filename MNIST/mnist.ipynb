{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm.script import tir as T\n",
    "from tvm.script import relax as R\n",
    "from tvm import relay\n",
    "from tvm import relax, topi\n",
    "import numpy as np\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MNIST:\n",
    "    @T.prim_func\n",
    "    def div255(X: T.Buffer((1,1,28,28), \"float32\"),\n",
    "               Y: T.Buffer((28,28), \"float32\")):\n",
    "        for i, j in T.grid(28,28):\n",
    "            with T.block(\"Y\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", (i,j))\n",
    "                Y[vi, vj] = X[0,0,vi, vj] * T.float32(1/255)\n",
    "\n",
    "    @T.prim_func\n",
    "    def Conv2DRelu_1(X: T.Buffer((28,28),\"float32\"),\n",
    "                     W: T.Buffer((8, 1, 5, 5), \"float32\"),\n",
    "                     B: T.Buffer((8,), \"float32\"),\n",
    "                     Y: T.Buffer((8, 28, 28), \"float32\")):\n",
    "        padded = T.alloc_buffer((32,32), \"float32\")\n",
    "        A = T.alloc_buffer((8,28,28), \"float32\")\n",
    "        for i, j in T.grid(32, 32):\n",
    "            with T.block(\"pad_init\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                padded[vi, vj] = 0\n",
    "        for i, j in T.grid(28, 28):\n",
    "            with T.block(\"copy\"):\n",
    "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
    "                padded[vi+2, vj+2] = X[vi, vj]\n",
    "        for q, i, j, di, dj in T.grid(8, 28, 28, 5, 5):\n",
    "            with T.block(\"conv\"):\n",
    "                vq, vi, vj, vdi, vdj = T.axis.remap(\"SSSRR\", [q, i, j, di, dj])\n",
    "                with T.init():\n",
    "                    A[vq, vi, vj] = 0\n",
    "                A[vq, vi, vj] += padded[vi+vdi, vj+vdj] * W[vq, 0, vdi, vdj]\n",
    "        for q, i, j in T.grid(8, 28, 28):\n",
    "            with T.block(\"biasrelu\"):\n",
    "                vq, vi, vj = T.axis.remap(\"SSS\", [q, i, j])\n",
    "                Y[vq, vi, vj] = T.max(A[vq, vi, vj] + B[vq], 0)\n",
    "\n",
    "    @T.prim_func\n",
    "    def MaxPooling2D_1(X: T.Buffer((8, 28, 28), \"float32\"),\n",
    "                       Y: T.Buffer((8, 14,14), \"float32\")):\n",
    "        for q, i, j in T.grid(8, 14, 14):\n",
    "            with T.block(\"Y\"):\n",
    "                vq, vi, vj = T.axis.remap(\"SSS\", [q,i,j])\n",
    "                Y[vq, vi, vj] = T.max(T.max(X[vq, 2*vi, 2*vj], X[vq, 2*vi, 2*vj+1]), T.max(X[vq, 2*vi+1, 2*vj], X[vq, 2*vi+1, 2*vj+1]))\n",
    "\n",
    "    @T.prim_func\n",
    "    def Conv2DRelu_2(X: T.Buffer((8, 14, 14),\"float32\"),\n",
    "                     W: T.Buffer((16, 8, 5, 5), \"float32\"),\n",
    "                     B: T.Buffer((16,), \"float32\"),\n",
    "                     Y: T.Buffer((16, 14, 14), \"float32\")):\n",
    "        padded = T.alloc_buffer((8,20,20), \"float32\")\n",
    "        A = T.alloc_buffer((16,14,14),\"float32\")\n",
    "        for k, i, j in T.grid(8, 20, 20):\n",
    "            with T.block(\"pad_init\"):\n",
    "                vk, vi, vj = T.axis.remap(\"SSS\", [k, i, j])\n",
    "                padded[vk, vi, vj] = 0\n",
    "        for k, i, j in T.grid(8, 14, 14):\n",
    "            with T.block(\"copy\"):\n",
    "                vk, vi, vj = T.axis.remap(\"SSS\", [k, i, j])\n",
    "                padded[vk, vi+2, vj+2] = X[vk, vi, vj]\n",
    "        for k, q, i, j, di, dj in T.grid(16, 8, 14, 14, 5, 5):\n",
    "            with T.block(\"conv\"):\n",
    "                vq, vi, vj, vk, vdi, vdj = T.axis.remap(\"SSSRRR\", [q, i, j, k, di, dj])\n",
    "                with T.init():\n",
    "                    A[vq, vi, vj] = 0\n",
    "                A[vq, vi, vj] += padded[vk, vi+vdi, vj+vdj] * W[vq, vk, vdi, vdj]\n",
    "        for q, i, j in T.grid(16, 14, 14):\n",
    "            with T.block(\"biasrelu\"):\n",
    "                vq, vi, vj = T.axis.remap(\"SSS\", [q, i, j])\n",
    "                Y[vq, vi, vj] = T.max(A[vq, vi, vj] + B[vq], 0)\n",
    "\n",
    "    @T.prim_func\n",
    "    def MaxPooling2D_2(X: T.Buffer((16, 14, 14), \"float32\"),\n",
    "                       Y: T.Buffer((16, 4, 4), \"float32\")):\n",
    "        for q, i, j, di, dj in T.grid(16, 4, 4, 3, 3):\n",
    "            with T.block(\"Y\"):\n",
    "                vq, vi, vj, vdi, vdj = T.axis.remap(\"SSSSS\", [q, i, j, di, dj])\n",
    "                with T.init():\n",
    "                    Y[vq, vi, vj] = 0\n",
    "                Y[vq, vi, vj] = T.max(Y[vq, vi, vj], X[vq, 3*vi+vdi, 3*vj+vdj])\n",
    "\n",
    "    @T.prim_func\n",
    "    def Dense(X: T.Buffer((16, 4, 4), \"float32\"),\n",
    "              W: T.Buffer((10, 256), \"float32\"),\n",
    "              B: T.Buffer((10,), \"float32\"),\n",
    "              Y: T.Buffer((10,), \"float32\")):\n",
    "        temp = T.alloc_buffer((10), \"float32\")\n",
    "        for i, k1, k2, k3 in T.grid(10, 16, 4, 4):\n",
    "            with T.block(\"mul\"):\n",
    "                vi, vk1, vk2, vk3 = T.axis.remap(\"SRRR\", [i, k1, k2, k3])\n",
    "                with T.init():\n",
    "                    temp[vi] = 0\n",
    "                temp[vi] = temp[vi] + X[vk1, vk2, vk3]*W[vi, 16*vk1+4*vk2+vk3]\n",
    "        for i in range(10):\n",
    "            with T.block(\"bias\"):\n",
    "                vi = T.axis.spatial(10, i)\n",
    "                Y[vi] = temp[vi] + B[vi]\n",
    "\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((1, 1, 28, 28), \"float32\"),\n",
    "             w0: R.Tensor((8, 1, 5, 5), \"float32\"),\n",
    "             b0: R.Tensor((8,), \"float32\"),\n",
    "             w1: R.Tensor((16, 8, 5, 5), \"float32\"),\n",
    "             b1: R.Tensor((16,), \"float32\"),\n",
    "             w2: R.Tensor((10, 256), \"float32\"),\n",
    "             b2: R.Tensor((10,), \"float32\")\n",
    "             ):\n",
    "        with R.dataflow():\n",
    "            lv0 = R.call_dps_packed(\"div255\", (x, ), R.Tensor((28, 28), \"float32\"))\n",
    "            lv1 = R.call_dps_packed(\"Conv2DRelu_1\", (lv0, w0, b0), R.Tensor((8, 28, 28), \"float32\"))\n",
    "            lv2 = R.call_dps_packed(\"MaxPooling2D_1\", (lv1, ), R.Tensor((8, 14, 14), \"float32\"))\n",
    "            lv3 = R.call_dps_packed(\"Conv2DRelu_2\", (lv2, w1, b1), R.Tensor((16, 14, 14), \"float32\"))\n",
    "            lv4 = R.call_dps_packed(\"MaxPooling2D_2\", (lv3, ), R.Tensor((16, 4, 4), \"float32\"))\n",
    "            out = R.call_dps_packed(\"Dense\", (lv4, w2, b2), R.Tensor((10,), \"float32\"))\n",
    "            R.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># from tvm.script import ir as I</span>\n",
       "<span class=\"c1\"># from tvm.script import tir as T</span>\n",
       "<span class=\"c1\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span class=\"nd\">@I</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
       "<span class=\"k\">class</span><span class=\"w\"> </span><span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">Conv2DRelu_1</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">W</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">Y</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)):</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span class=\"n\">padded</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">((</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">))</span>\n",
       "        <span class=\"n\">A</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">))</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">,</span> <span class=\"mi\">32</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;pad_init&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">()</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;copy&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">di</span><span class=\"p\">,</span> <span class=\"n\">dj</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;conv&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vdj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSSRR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">di</span><span class=\"p\">,</span> <span class=\"n\">dj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"n\">vdj</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vdj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"n\">vdj</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vdj</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;biasrelu&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">))</span>\n",
       "\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">Conv2DRelu_2</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">W</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">Y</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)):</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span class=\"n\">padded</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">))</span>\n",
       "        <span class=\"n\">A</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">))</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;pad_init&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">()</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;copy&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">di</span><span class=\"p\">,</span> <span class=\"n\">dj</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;conv&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vdj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSSRRR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">di</span><span class=\"p\">,</span> <span class=\"n\">dj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"n\">vdj</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vdj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">padded</span><span class=\"p\">[</span><span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"n\">vdj</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vdj</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;biasrelu&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">))</span>\n",
       "\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">Dense</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">W</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">Y</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)):</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span class=\"n\">temp</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,))</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">k1</span><span class=\"p\">,</span> <span class=\"n\">k2</span><span class=\"p\">,</span> <span class=\"n\">k3</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;mul&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk1</span><span class=\"p\">,</span> <span class=\"n\">vk2</span><span class=\"p\">,</span> <span class=\"n\">vk3</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SRRR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">k1</span><span class=\"p\">,</span> <span class=\"n\">k2</span><span class=\"p\">,</span> <span class=\"n\">k3</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vk1</span><span class=\"p\">,</span> <span class=\"n\">vk2</span><span class=\"p\">,</span> <span class=\"n\">vk3</span><span class=\"p\">],</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"mi\">16</span> <span class=\"o\">*</span> <span class=\"n\">vk1</span> <span class=\"o\">+</span> <span class=\"mi\">4</span> <span class=\"o\">*</span> <span class=\"n\">vk2</span> <span class=\"o\">+</span> <span class=\"n\">vk3</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">temp</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">temp</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">temp</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">temp</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vk1</span><span class=\"p\">,</span> <span class=\"n\">vk2</span><span class=\"p\">,</span> <span class=\"n\">vk3</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">W</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"mi\">16</span> <span class=\"o\">*</span> <span class=\"n\">vk1</span> <span class=\"o\">+</span> <span class=\"mi\">4</span> <span class=\"o\">*</span> <span class=\"n\">vk2</span> <span class=\"o\">+</span> <span class=\"n\">vk3</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;bias&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">temp</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">temp</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">]</span>\n",
       "\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">MaxPooling2D_1</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">Y</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)):</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">*</span> <span class=\"mi\">2</span><span class=\"p\">:</span><span class=\"n\">vi</span> <span class=\"o\">*</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">*</span> <span class=\"mi\">2</span><span class=\"p\">:</span><span class=\"n\">vj</span> <span class=\"o\">*</span> <span class=\"mi\">2</span> <span class=\"o\">+</span> <span class=\"mi\">2</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">]),</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">2</span> <span class=\"o\">*</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">]))</span>\n",
       "\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">MaxPooling2D_2</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">Y</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)):</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">di</span><span class=\"p\">,</span> <span class=\"n\">dj</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"n\">vdj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSSSS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">di</span><span class=\"p\">,</span> <span class=\"n\">dj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"mi\">3</span> <span class=\"o\">*</span> <span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"mi\">3</span> <span class=\"o\">*</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"n\">vdj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"n\">vq</span><span class=\"p\">,</span> <span class=\"mi\">3</span> <span class=\"o\">*</span> <span class=\"n\">vi</span> <span class=\"o\">+</span> <span class=\"n\">vdi</span><span class=\"p\">,</span> <span class=\"mi\">3</span> <span class=\"o\">*</span> <span class=\"n\">vj</span> <span class=\"o\">+</span> <span class=\"n\">vdj</span><span class=\"p\">])</span>\n",
       "\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">div255</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">Y</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">((</span><span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)):</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">X</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mf\">0.0039215686274509803</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"nd\">@R</span><span class=\"o\">.</span><span class=\"n\">function</span>\n",
       "    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">main</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b0</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b1</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">w2</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">),</span> <span class=\"n\">b2</span><span class=\"p\">:</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span> <span class=\"o\">-&gt;</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">with</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">dataflow</span><span class=\"p\">():</span>\n",
       "            <span class=\"n\">lv0</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_dps_packed</span><span class=\"p\">(</span><span class=\"s2\">&quot;div255&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">lv1</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_dps_packed</span><span class=\"p\">(</span><span class=\"s2\">&quot;Conv2DRelu_1&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv0</span><span class=\"p\">,</span> <span class=\"n\">w0</span><span class=\"p\">,</span> <span class=\"n\">b0</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">,</span> <span class=\"mi\">28</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">lv2</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_dps_packed</span><span class=\"p\">(</span><span class=\"s2\">&quot;MaxPooling2D_1&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv1</span><span class=\"p\">,),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">lv3</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_dps_packed</span><span class=\"p\">(</span><span class=\"s2\">&quot;Conv2DRelu_2&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv2</span><span class=\"p\">,</span> <span class=\"n\">w1</span><span class=\"p\">,</span> <span class=\"n\">b1</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">,</span> <span class=\"mi\">14</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">lv4</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_dps_packed</span><span class=\"p\">(</span><span class=\"s2\">&quot;MaxPooling2D_2&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv3</span><span class=\"p\">,),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">call_dps_packed</span><span class=\"p\">(</span><span class=\"s2\">&quot;Dense&quot;</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"n\">lv4</span><span class=\"p\">,</span> <span class=\"n\">w2</span><span class=\"p\">,</span> <span class=\"n\">b2</span><span class=\"p\">),</span> <span class=\"n\">out_sinfo</span><span class=\"o\">=</span><span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">((</span><span class=\"mi\">10</span><span class=\"p\">,),</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">R</span><span class=\"o\">.</span><span class=\"n\">output</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">out</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} from tvm.script import ir as I}\n",
       "\\PY{c+c1}{\\PYZsh{} from tvm.script import tir as T}\n",
       "\\PY{c+c1}{\\PYZsh{} from tvm.script import relax as R}\n",
       "\n",
       "\\PY{n+nd}{@I}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n",
       "\\PY{k}{class}\\PY{+w}{ }\\PY{n+nc}{Module}\\PY{p}{:}\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{Conv2DRelu\\PYZus{}1}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{W}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Y}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{}):}\n",
       "        \\PY{n}{padded} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{,} \\PY{l+m+mi}{32}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n}{A} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{,} \\PY{l+m+mi}{32}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{pad\\PYZus{}init}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{padded}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{padded}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mf}{0.0}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{copy}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{padded}\\PY{p}{[}\\PY{n}{vi} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{padded}\\PY{p}{[}\\PY{n}{vi} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{]} \\PY{o}{=} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{di}\\PY{p}{,} \\PY{n}{dj} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{conv}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vdj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSSRR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{di}\\PY{p}{,} \\PY{n}{dj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{padded}\\PY{p}{[}\\PY{n}{vi} \\PY{o}{+} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{+} \\PY{n}{vdj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{l+m+mi}{0}\\PY{p}{,} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vdj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mf}{0.0}\\PY{p}{)}\n",
       "                \\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{padded}\\PY{p}{[}\\PY{n}{vi} \\PY{o}{+} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{+} \\PY{n}{vdj}\\PY{p}{]} \\PY{o}{*} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{l+m+mi}{0}\\PY{p}{,} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vdj}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{biasrelu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mf}{0.0}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{Conv2DRelu\\PYZus{}2}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{W}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Y}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{}):}\n",
       "        \\PY{n}{padded} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{20}\\PY{p}{,} \\PY{l+m+mi}{20}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n}{A} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{k}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{20}\\PY{p}{,} \\PY{l+m+mi}{20}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{pad\\PYZus{}init}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{k}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{padded}\\PY{p}{[}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{padded}\\PY{p}{[}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mf}{0.0}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{k}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{copy}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{k}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{padded}\\PY{p}{[}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{padded}\\PY{p}{[}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{]} \\PY{o}{=} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{k}\\PY{p}{,} \\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{di}\\PY{p}{,} \\PY{n}{dj} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{conv}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vdj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSSRRR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k}\\PY{p}{,} \\PY{n}{di}\\PY{p}{,} \\PY{n}{dj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{padded}\\PY{p}{[}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{+} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{+} \\PY{n}{vdj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vdj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mf}{0.0}\\PY{p}{)}\n",
       "                \\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{padded}\\PY{p}{[}\\PY{n}{vk}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{+} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{+} \\PY{n}{vdj}\\PY{p}{]} \\PY{o}{*} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vdj}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{biasrelu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mf}{0.0}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{Dense}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{W}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{256}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Y}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{}):}\n",
       "        \\PY{n}{temp} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{k1}\\PY{p}{,} \\PY{n}{k2}\\PY{p}{,} \\PY{n}{k3} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{mul}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk1}\\PY{p}{,} \\PY{n}{vk2}\\PY{p}{,} \\PY{n}{vk3} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SRRR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{k1}\\PY{p}{,} \\PY{n}{k2}\\PY{p}{,} \\PY{n}{k3}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vk1}\\PY{p}{,} \\PY{n}{vk2}\\PY{p}{,} \\PY{n}{vk3}\\PY{p}{]}\\PY{p}{,} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{l+m+mi}{16} \\PY{o}{*} \\PY{n}{vk1} \\PY{o}{+} \\PY{l+m+mi}{4} \\PY{o}{*} \\PY{n}{vk2} \\PY{o}{+} \\PY{n}{vk3}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{temp}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{temp}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mf}{0.0}\\PY{p}{)}\n",
       "                \\PY{n}{temp}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]} \\PY{o}{=} \\PY{n}{temp}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]} \\PY{o}{+} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vk1}\\PY{p}{,} \\PY{n}{vk2}\\PY{p}{,} \\PY{n}{vk3}\\PY{p}{]} \\PY{o}{*} \\PY{n}{W}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{l+m+mi}{16} \\PY{o}{*} \\PY{n}{vk1} \\PY{o}{+} \\PY{l+m+mi}{4} \\PY{o}{*} \\PY{n}{vk2} \\PY{o}{+} \\PY{n}{vk3}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{bias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{n}{i}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{temp}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]} \\PY{o}{=} \\PY{n}{temp}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]} \\PY{o}{+} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{]}\n",
       "\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{MaxPooling2D\\PYZus{}1}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Y}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{}):}\n",
       "        \\PY{k}{for} \\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{*} \\PY{l+m+mi}{2}\\PY{p}{:}\\PY{n}{vi} \\PY{o}{*} \\PY{l+m+mi}{2} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{*} \\PY{l+m+mi}{2}\\PY{p}{:}\\PY{n}{vj} \\PY{o}{*} \\PY{l+m+mi}{2} \\PY{o}{+} \\PY{l+m+mi}{2}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{l+m+mi}{2} \\PY{o}{*} \\PY{n}{vi}\\PY{p}{,} \\PY{l+m+mi}{2} \\PY{o}{*} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{l+m+mi}{2} \\PY{o}{*} \\PY{n}{vi}\\PY{p}{,} \\PY{l+m+mi}{2} \\PY{o}{*} \\PY{n}{vj} \\PY{o}{+} \\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{)}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{l+m+mi}{2} \\PY{o}{*} \\PY{n}{vi} \\PY{o}{+} \\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{2} \\PY{o}{*} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{l+m+mi}{2} \\PY{o}{*} \\PY{n}{vi} \\PY{o}{+} \\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{2} \\PY{o}{*} \\PY{n}{vj} \\PY{o}{+} \\PY{l+m+mi}{1}\\PY{p}{]}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{MaxPooling2D\\PYZus{}2}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Y}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{}):}\n",
       "        \\PY{k}{for} \\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{di}\\PY{p}{,} \\PY{n}{dj} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{3}\\PY{p}{,} \\PY{l+m+mi}{3}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vdi}\\PY{p}{,} \\PY{n}{vdj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSSSS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{q}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{di}\\PY{p}{,} \\PY{n}{dj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{l+m+mi}{3} \\PY{o}{*} \\PY{n}{vi} \\PY{o}{+} \\PY{n}{vdi}\\PY{p}{,} \\PY{l+m+mi}{3} \\PY{o}{*} \\PY{n}{vj} \\PY{o}{+} \\PY{n}{vdj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mf}{0.0}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{X}\\PY{p}{[}\\PY{n}{vq}\\PY{p}{,} \\PY{l+m+mi}{3} \\PY{o}{*} \\PY{n}{vi} \\PY{o}{+} \\PY{n}{vdi}\\PY{p}{,} \\PY{l+m+mi}{3} \\PY{o}{*} \\PY{n}{vj} \\PY{o}{+} \\PY{n}{vdj}\\PY{p}{]}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{div255}\\PY{p}{(}\\PY{n}{X}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{Y}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{}):}\n",
       "        \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{X}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,} \\PY{l+m+mi}{0}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{X}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{,} \\PY{l+m+mi}{0}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{*} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mf}{0.0039215686274509803}\\PY{p}{)}\n",
       "\n",
       "    \\PY{n+nd}{@R}\\PY{o}{.}\\PY{n}{function}\n",
       "    \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{main}\\PY{p}{(}\\PY{n}{x}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{w2}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{256}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,} \\PY{n}{b2}\\PY{p}{:} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{with} \\PY{n}{R}\\PY{o}{.}\\PY{n}{dataflow}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{n}{lv0} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}dps\\PYZus{}packed}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{div255}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{x}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{lv1} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}dps\\PYZus{}packed}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Conv2DRelu\\PYZus{}1}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv0}\\PY{p}{,} \\PY{n}{w0}\\PY{p}{,} \\PY{n}{b0}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{,} \\PY{l+m+mi}{28}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{lv2} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}dps\\PYZus{}packed}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{MaxPooling2D\\PYZus{}1}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv1}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{lv3} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}dps\\PYZus{}packed}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Conv2DRelu\\PYZus{}2}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv2}\\PY{p}{,} \\PY{n}{w1}\\PY{p}{,} \\PY{n}{b1}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{,} \\PY{l+m+mi}{14}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{lv4} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}dps\\PYZus{}packed}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{MaxPooling2D\\PYZus{}2}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv3}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{,} \\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{out} \\PY{o}{=} \\PY{n}{R}\\PY{o}{.}\\PY{n}{call\\PYZus{}dps\\PYZus{}packed}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Dense}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{(}\\PY{n}{lv4}\\PY{p}{,} \\PY{n}{w2}\\PY{p}{,} \\PY{n}{b2}\\PY{p}{)}\\PY{p}{,} \\PY{n}{out\\PYZus{}sinfo}\\PY{o}{=}\\PY{n}{R}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{(}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,}\\PY{p}{)}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{)}\n",
       "            \\PY{n}{R}\\PY{o}{.}\\PY{n}{output}\\PY{p}{(}\\PY{n}{out}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{out}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# from tvm.script import ir as I\n",
       "# from tvm.script import tir as T\n",
       "# from tvm.script import relax as R\n",
       "\n",
       "@I.ir_module\n",
       "class Module:\n",
       "    @T.prim_func\n",
       "    def Conv2DRelu_1(X: T.Buffer((28, 28), \"float32\"), W: T.Buffer((8, 1, 5, 5), \"float32\"), B: T.Buffer((8,), \"float32\"), Y: T.Buffer((8, 28, 28), \"float32\")):\n",
       "        # with T.block(\"root\"):\n",
       "        padded = T.alloc_buffer((32, 32))\n",
       "        A = T.alloc_buffer((8, 28, 28))\n",
       "        for i, j in T.grid(32, 32):\n",
       "            with T.block(\"pad_init\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads()\n",
       "                T.writes(padded[vi, vj])\n",
       "                padded[vi, vj] = T.float32(0.0)\n",
       "        for i, j in T.grid(28, 28):\n",
       "            with T.block(\"copy\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads(X[vi, vj])\n",
       "                T.writes(padded[vi + 2, vj + 2])\n",
       "                padded[vi + 2, vj + 2] = X[vi, vj]\n",
       "        for q, i, j, di, dj in T.grid(8, 28, 28, 5, 5):\n",
       "            with T.block(\"conv\"):\n",
       "                vq, vi, vj, vdi, vdj = T.axis.remap(\"SSSRR\", [q, i, j, di, dj])\n",
       "                T.reads(padded[vi + vdi, vj + vdj], W[vq, 0, vdi, vdj])\n",
       "                T.writes(A[vq, vi, vj])\n",
       "                with T.init():\n",
       "                    A[vq, vi, vj] = T.float32(0.0)\n",
       "                A[vq, vi, vj] = A[vq, vi, vj] + padded[vi + vdi, vj + vdj] * W[vq, 0, vdi, vdj]\n",
       "        for q, i, j in T.grid(8, 28, 28):\n",
       "            with T.block(\"biasrelu\"):\n",
       "                vq, vi, vj = T.axis.remap(\"SSS\", [q, i, j])\n",
       "                T.reads(A[vq, vi, vj], B[vq])\n",
       "                T.writes(Y[vq, vi, vj])\n",
       "                Y[vq, vi, vj] = T.max(A[vq, vi, vj] + B[vq], T.float32(0.0))\n",
       "\n",
       "    @T.prim_func\n",
       "    def Conv2DRelu_2(X: T.Buffer((8, 14, 14), \"float32\"), W: T.Buffer((16, 8, 5, 5), \"float32\"), B: T.Buffer((16,), \"float32\"), Y: T.Buffer((16, 14, 14), \"float32\")):\n",
       "        # with T.block(\"root\"):\n",
       "        padded = T.alloc_buffer((8, 20, 20))\n",
       "        A = T.alloc_buffer((16, 14, 14))\n",
       "        for k, i, j in T.grid(8, 20, 20):\n",
       "            with T.block(\"pad_init\"):\n",
       "                vk, vi, vj = T.axis.remap(\"SSS\", [k, i, j])\n",
       "                T.reads()\n",
       "                T.writes(padded[vk, vi, vj])\n",
       "                padded[vk, vi, vj] = T.float32(0.0)\n",
       "        for k, i, j in T.grid(8, 14, 14):\n",
       "            with T.block(\"copy\"):\n",
       "                vk, vi, vj = T.axis.remap(\"SSS\", [k, i, j])\n",
       "                T.reads(X[vk, vi, vj])\n",
       "                T.writes(padded[vk, vi + 2, vj + 2])\n",
       "                padded[vk, vi + 2, vj + 2] = X[vk, vi, vj]\n",
       "        for k, q, i, j, di, dj in T.grid(16, 8, 14, 14, 5, 5):\n",
       "            with T.block(\"conv\"):\n",
       "                vq, vi, vj, vk, vdi, vdj = T.axis.remap(\"SSSRRR\", [q, i, j, k, di, dj])\n",
       "                T.reads(padded[vk, vi + vdi, vj + vdj], W[vq, vk, vdi, vdj])\n",
       "                T.writes(A[vq, vi, vj])\n",
       "                with T.init():\n",
       "                    A[vq, vi, vj] = T.float32(0.0)\n",
       "                A[vq, vi, vj] = A[vq, vi, vj] + padded[vk, vi + vdi, vj + vdj] * W[vq, vk, vdi, vdj]\n",
       "        for q, i, j in T.grid(16, 14, 14):\n",
       "            with T.block(\"biasrelu\"):\n",
       "                vq, vi, vj = T.axis.remap(\"SSS\", [q, i, j])\n",
       "                T.reads(A[vq, vi, vj], B[vq])\n",
       "                T.writes(Y[vq, vi, vj])\n",
       "                Y[vq, vi, vj] = T.max(A[vq, vi, vj] + B[vq], T.float32(0.0))\n",
       "\n",
       "    @T.prim_func\n",
       "    def Dense(X: T.Buffer((16, 4, 4), \"float32\"), W: T.Buffer((10, 256), \"float32\"), B: T.Buffer((10,), \"float32\"), Y: T.Buffer((10,), \"float32\")):\n",
       "        # with T.block(\"root\"):\n",
       "        temp = T.alloc_buffer((10,))\n",
       "        for i, k1, k2, k3 in T.grid(10, 16, 4, 4):\n",
       "            with T.block(\"mul\"):\n",
       "                vi, vk1, vk2, vk3 = T.axis.remap(\"SRRR\", [i, k1, k2, k3])\n",
       "                T.reads(X[vk1, vk2, vk3], W[vi, 16 * vk1 + 4 * vk2 + vk3])\n",
       "                T.writes(temp[vi])\n",
       "                with T.init():\n",
       "                    temp[vi] = T.float32(0.0)\n",
       "                temp[vi] = temp[vi] + X[vk1, vk2, vk3] * W[vi, 16 * vk1 + 4 * vk2 + vk3]\n",
       "        for i in range(10):\n",
       "            with T.block(\"bias\"):\n",
       "                vi = T.axis.spatial(10, i)\n",
       "                T.reads(temp[vi], B[vi])\n",
       "                T.writes(Y[vi])\n",
       "                Y[vi] = temp[vi] + B[vi]\n",
       "\n",
       "    @T.prim_func\n",
       "    def MaxPooling2D_1(X: T.Buffer((8, 28, 28), \"float32\"), Y: T.Buffer((8, 14, 14), \"float32\")):\n",
       "        # with T.block(\"root\"):\n",
       "        for q, i, j in T.grid(8, 14, 14):\n",
       "            with T.block(\"Y\"):\n",
       "                vq, vi, vj = T.axis.remap(\"SSS\", [q, i, j])\n",
       "                T.reads(X[vq, vi * 2:vi * 2 + 2, vj * 2:vj * 2 + 2])\n",
       "                T.writes(Y[vq, vi, vj])\n",
       "                Y[vq, vi, vj] = T.max(T.max(X[vq, 2 * vi, 2 * vj], X[vq, 2 * vi, 2 * vj + 1]), T.max(X[vq, 2 * vi + 1, 2 * vj], X[vq, 2 * vi + 1, 2 * vj + 1]))\n",
       "\n",
       "    @T.prim_func\n",
       "    def MaxPooling2D_2(X: T.Buffer((16, 14, 14), \"float32\"), Y: T.Buffer((16, 4, 4), \"float32\")):\n",
       "        # with T.block(\"root\"):\n",
       "        for q, i, j, di, dj in T.grid(16, 4, 4, 3, 3):\n",
       "            with T.block(\"Y\"):\n",
       "                vq, vi, vj, vdi, vdj = T.axis.remap(\"SSSSS\", [q, i, j, di, dj])\n",
       "                T.reads(X[vq, 3 * vi + vdi, 3 * vj + vdj])\n",
       "                T.writes(Y[vq, vi, vj])\n",
       "                with T.init():\n",
       "                    Y[vq, vi, vj] = T.float32(0.0)\n",
       "                Y[vq, vi, vj] = T.max(Y[vq, vi, vj], X[vq, 3 * vi + vdi, 3 * vj + vdj])\n",
       "\n",
       "    @T.prim_func\n",
       "    def div255(X: T.Buffer((1, 1, 28, 28), \"float32\"), Y: T.Buffer((28, 28), \"float32\")):\n",
       "        # with T.block(\"root\"):\n",
       "        for i, j in T.grid(28, 28):\n",
       "            with T.block(\"Y\"):\n",
       "                vi, vj = T.axis.remap(\"SS\", [i, j])\n",
       "                T.reads(X[0, 0, vi, vj])\n",
       "                T.writes(Y[vi, vj])\n",
       "                Y[vi, vj] = X[0, 0, vi, vj] * T.float32(0.0039215686274509803)\n",
       "\n",
       "    @R.function\n",
       "    def main(x: R.Tensor((1, 1, 28, 28), dtype=\"float32\"), w0: R.Tensor((8, 1, 5, 5), dtype=\"float32\"), b0: R.Tensor((8,), dtype=\"float32\"), w1: R.Tensor((16, 8, 5, 5), dtype=\"float32\"), b1: R.Tensor((16,), dtype=\"float32\"), w2: R.Tensor((10, 256), dtype=\"float32\"), b2: R.Tensor((10,), dtype=\"float32\")) -> R.Tensor((10,), dtype=\"float32\"):\n",
       "        with R.dataflow():\n",
       "            lv0 = R.call_dps_packed(\"div255\", (x,), out_sinfo=R.Tensor((28, 28), dtype=\"float32\"))\n",
       "            lv1 = R.call_dps_packed(\"Conv2DRelu_1\", (lv0, w0, b0), out_sinfo=R.Tensor((8, 28, 28), dtype=\"float32\"))\n",
       "            lv2 = R.call_dps_packed(\"MaxPooling2D_1\", (lv1,), out_sinfo=R.Tensor((8, 14, 14), dtype=\"float32\"))\n",
       "            lv3 = R.call_dps_packed(\"Conv2DRelu_2\", (lv2, w1, b1), out_sinfo=R.Tensor((16, 14, 14), dtype=\"float32\"))\n",
       "            lv4 = R.call_dps_packed(\"MaxPooling2D_2\", (lv3,), out_sinfo=R.Tensor((16, 4, 4), dtype=\"float32\"))\n",
       "            out = R.call_dps_packed(\"Dense\", (lv4, w2, b2), out_sinfo=R.Tensor((10,), dtype=\"float32\"))\n",
       "            R.output(out)\n",
       "        return out"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch=tvm.tir.Schedule(MNIST)\n",
    "IPython.display.Code(sch.mod.script(), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"mnist/mnist-8.onnx\")\n",
    "\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, {\"Input3\": (1,1,28,28)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 4, 4, 10)\n",
      "(16, 8, 5, 5)\n",
      "(8, 1, 5, 5)\n",
      "(8, 1, 1)\n",
      "(16, 1, 1)\n",
      "(2,)\n",
      "(2,)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 4, 4, 10)\n",
      "(16, 8, 5, 5)\n",
      "(8, 1, 5, 5)\n",
      "(8, 1, 1)\n",
      "(16, 1, 1)\n",
      "(2,)\n",
      "(2,)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "for initializer in onnx_model.graph.initializer:\n",
    "    weights.append(onnx.numpy_helper.to_array(initializer))\n",
    "\n",
    "for w in weights:\n",
    "    print(w.shape)\n",
    "\n",
    "weights[0] = weights[0].reshape((256,10)).transpose()\n",
    "weights[3] = weights[3].reshape((8,))\n",
    "weights[4] = weights[4].reshape((16,))\n",
    "weights[7] = weights[7].reshape((10,))\n",
    "\n",
    "params = [weights[2], weights[3], weights[1], weights[4], weights[0], weights[7]]\n",
    "\n",
    "params = [tvm.nd.array(w, device=tvm.cpu()) for w in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = relax.build(MNIST, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu(), profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00457341  0.16657507 -0.40194058 -0.21732956  0.14365725  0.3357103\n",
      " -0.51385933  0.09719408 -0.23806621  0.14697815]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHMhJREFUeJzt3X9sVfX9x/HX7a8r2PayCv0lBQuiTPmxDaVrUMTRADVxoGRR8Q8wBKIWI1an6aai25JuuPA1GIaZcTATUeciEM3CplXKnC0bCGFEbSjrpA5aZpfeWy5Savv5/kHodqUgn8u9fbfl+UhO0nvv533Pmw+nffX0nvu5AeecEwAA/SzFugEAwMWJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJNOsGvqqnp0eHDx9WVlaWAoGAdTsAAE/OOXV0dKiwsFApKWc/zxlwAXT48GEVFRVZtwEAuEDNzc0aPXr0WR8fcAGUlZUlSQoGg15nQF9++WWyWgKAi9qll17qNd45p0gk0vvz/GySFkDr1q3TM888o5aWFk2dOlXPPfecpk+f/rV1p0MnEAh4BRB/rgOA5Ij35+vX1SXlIoTXXntNlZWVWrVqlT788ENNnTpVc+fO1dGjR5OxOwDAIJSUAFqzZo2WLVume+65R9dcc42ef/55DR8+XL/5zW+SsTsAwCCU8AA6efKkdu/erbKysv/uJCVFZWVlqqurO2N8Z2enIpFIzAYAGPoSHkCff/65uru7lZeXF3N/Xl6eWlpazhhfXV2tUCjUu3EFHABcHMzfiFpVVaVwONy7NTc3W7cEAOgHCb8KbuTIkUpNTVVra2vM/a2trcrPzz9jfDAYVDAYTHQbAIABLuFnQBkZGZo2bZpqamp67+vp6VFNTY1KS0sTvTsAwCCVlPcBVVZWavHixbruuus0ffp0Pfvss4pGo7rnnnuSsTsAwCCUlAC644479O9//1tPPvmkWlpa9K1vfUvbtm0748IEAMDFK+Ccc9ZN/K9IJKJQKKS0tDSvd992dXUlsSsAuHhlZmZ6jXfOKRqNKhwOKzs7+6zjzK+CAwBcnAggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGAi4QH01FNPKRAIxGwTJ05M9G4AAINcWjKe9Nprr9U777zz352kJWU3AIBBLCnJkJaWpvz8/GQ8NQBgiEjKa0AHDhxQYWGhxo0bp7vvvluHDh0669jOzk5FIpGYDQAw9CU8gEpKSrRx40Zt27ZN69evV1NTk2688UZ1dHT0Ob66ulqhUKh3KyoqSnRLAIABKOCcc8ncQXt7u8aOHas1a9Zo6dKlZzze2dmpzs7O3tuRSERFRUVKS0tTIBA47/10dXUlpF8AQKzMzEyv8c45RaNRhcNhZWdnn3Vc0q8OGDFihK666io1Njb2+XgwGFQwGEx2GwCAASbp7wM6duyYDh48qIKCgmTvCgAwiCQ8gB555BHV1tbqn//8pz744APddtttSk1N1V133ZXoXQEABrGE/wnus88+01133aW2tjaNGjVKN9xwg+rr6zVq1KhE7woAMIglPIBeffXVRD8lPKSmpnrXZGRkxLWveK5fiacmngtMenp6vGsA9C/WggMAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGAi6R9Ih/ilp6d718yfP9+75vvf/753jSR98cUX3jXhcNi75r333vOuaW5u9q6Jt46FT/tXd3e3d83/fupysveF88cZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARMA556yb+F+RSEShUEhpaWkKBALnXdfV1ZXErmxkZ2d71/z+97/3rikpKfGukfpvpeB4/m87Ojri2ldTU5N3zZdffuld43NsX0hNvPrrx0I8x9A//vEP75oNGzZ410jSnj17vGsG2I/UhMjMzPQa75xTNBpVOBw+588xzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYSLNuAGd34sQJ75q1a9d610ycONG7RpKOHj3qXXP55Zd710yePNm7Ztq0ad41kvTtb3/bu6atrc27ZtSoUd41KSn99/viyZMnvWsikYh3zZgxY/plP83Nzd41krRv3z7vmngWp71YcQYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAxIBdjNQ5Z92CuXgWhNy2bZt3TU1NjXeNFN+ii2lp/odcMBj0rsnPz/eukaRx48Z513z66afeNRMmTPCuiWfu4v0+6ujo8K7p6enxrnn55Ze9a9LT071rPv/8c+8aiZ9DycYZEADABAEEADDhHUA7duzQrbfeqsLCQgUCAW3ZsiXmceecnnzySRUUFGjYsGEqKyvTgQMHEtUvAGCI8A6gaDSqqVOnat26dX0+vnr1aq1du1bPP/+8du7cqUsvvVRz586N68PVAABDl/ermuXl5SovL+/zMeecnn32WT3++OOaP3++JOmll15SXl6etmzZojvvvPPCugUADBkJfQ2oqalJLS0tKisr670vFAqppKREdXV1fdZ0dnYqEonEbACAoS+hAdTS0iJJysvLi7k/Ly+v97Gvqq6uVigU6t2KiooS2RIAYIAyvwquqqpK4XC4d2tubrZuCQDQDxIaQKff/Nfa2hpzf2tr61nfGBgMBpWdnR2zAQCGvoQGUHFxsfLz82PeWR+JRLRz506VlpYmclcAgEHO+yq4Y8eOqbGxsfd2U1OT9u7dq5ycHI0ZM0YrV67Uz372M02YMEHFxcV64oknVFhYqAULFiSybwDAIOcdQLt27dLNN9/ce7uyslKStHjxYm3cuFGPPvqootGoli9frvb2dt1www3atm2bLrnkksR1DQAY9AJugK22F4lEFAqFlJaWpkAgcN51XV1dSewKF4vU1FTvmu7ubu+aeBYW9fl+OC3eb++MjAzvmnje57dmzRrvmr/97W/eNUuXLvWukaRDhw7FVTfUZGZmeo13zikajSocDp/zdX3zq+AAABcnAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJ/yV5gSEsnpWt4/Hll1/2y37iddVVV3nXPPbYY9418cz3iy++6F3zr3/9y7sGyccZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMsRgoMYdnZ2XHVLVq0yLvmiiuu8K755JNPvGs++ugj75r+WmQWfjgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYILFSIFBIiXF//fFGTNmxLWv5cuXe9e0t7d71/z4xz/2rvn444+9azAwcQYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAxIBdjNQ5Z90CMKAEg0HvmptuuimufWVmZnrX/OEPf/Cu+fOf/+xd09XV5V2DgYkzIACACQIIAGDCO4B27NihW2+9VYWFhQoEAtqyZUvM40uWLFEgEIjZ5s2bl6h+AQBDhHcARaNRTZ06VevWrTvrmHnz5unIkSO92yuvvHJBTQIAhh7vixDKy8tVXl5+zjHBYFD5+flxNwUAGPqS8hrQ9u3blZubq6uvvlr33Xef2trazjq2s7NTkUgkZgMADH0JD6B58+bppZdeUk1NjX7xi1+otrZW5eXl6u7u7nN8dXW1QqFQ71ZUVJTolgAAA1DC3wd055139n49efJkTZkyRePHj9f27ds1e/bsM8ZXVVWpsrKy93YkEiGEAOAikPTLsMeNG6eRI0eqsbGxz8eDwaCys7NjNgDA0Jf0APrss8/U1tamgoKCZO8KADCIeP8J7tixYzFnM01NTdq7d69ycnKUk5Ojp59+WgsXLlR+fr4OHjyoRx99VFdeeaXmzp2b0MYBAIObdwDt2rVLN998c+/t06/fLF68WOvXr9e+ffv029/+Vu3t7SosLNScOXP005/+NK51rAAAQ5d3AM2aNeucC4X+8Y9/vKCGTju9igKAU0aNGuVdc8MNN8S1r//85z/eNS+88IJ3TUdHh3cNhg7WggMAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmEj4R3ID+HrxfPLv0qVLvWuuueYa7xpJ+tOf/uRd88EHH3jX9PT0eNdg6OAMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkWIwUuUFqa/7fRLbfc4l1z//33e9e0t7d710jSCy+84F1z7NixuPaFixdnQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEywGCnwPwKBgHfNhAkTvGsefvhh75rs7Gzvmi1btnjXSFJ9fb13jXMurn3h4sUZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMDdjFSFjaEhZycHO+aZ555xrtmypQp3jV///vfvWt+/etfe9dIUjQajasO8MEZEADABAEEADDhFUDV1dW6/vrrlZWVpdzcXC1YsEANDQ0xY06cOKGKigpddtllyszM1MKFC9Xa2prQpgEAg59XANXW1qqiokL19fV6++231dXVpTlz5sT8vfihhx7Sm2++qddff121tbU6fPiwbr/99oQ3DgAY3LwuQti2bVvM7Y0bNyo3N1e7d+/WzJkzFQ6H9eKLL2rTpk363ve+J0nasGGDvvnNb6q+vl7f/e53E9c5AGBQu6DXgMLhsKT/Xjm0e/dudXV1qaysrHfMxIkTNWbMGNXV1fX5HJ2dnYpEIjEbAGDoizuAenp6tHLlSs2YMUOTJk2SJLW0tCgjI0MjRoyIGZuXl6eWlpY+n6e6ulqhUKh3KyoqirclAMAgEncAVVRUaP/+/Xr11VcvqIGqqiqFw+Herbm5+YKeDwAwOMT1RtQVK1borbfe0o4dOzR69Oje+/Pz83Xy5Em1t7fHnAW1trYqPz+/z+cKBoMKBoPxtAEAGMS8zoCcc1qxYoU2b96sd999V8XFxTGPT5s2Tenp6aqpqem9r6GhQYcOHVJpaWliOgYADAleZ0AVFRXatGmTtm7dqqysrN7XdUKhkIYNG6ZQKKSlS5eqsrJSOTk5ys7O1gMPPKDS0lKugAMAxPAKoPXr10uSZs2aFXP/hg0btGTJEknS//3f/yklJUULFy5UZ2en5s6dq1/96lcJaRYAMHQE3ABb9TMSiSgUCiktLU2BQOC867q6upLYFQablJT4rq+58cYbvWu2bt3qXXPixAnvmpUrV3rXvPHGG941knTy5Mm46jA0ZWZmeo13zikajSocDis7O/us41gLDgBgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgIq5PRAUGumuvvTauul/+8pfeNampqd41a9eu9a558803vWtY1RoDGWdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATLAYKQa84cOHe9f84Ac/iGtfU6ZM8a45fvy4d01dXZ13TTQa9a4BBjLOgAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhgMVL0q5QU/995SkpKvGsWLVrkXSNJGRkZ3jUdHR3eNV1dXd41wFDDGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATLEaKfpWenu5dc91113nXFBYWetdIUk9Pj3dNQ0ODd00kEvGuAYYazoAAACYIIACACa8Aqq6u1vXXX6+srCzl5uZqwYIFZ/z5YdasWQoEAjHbvffem9CmAQCDn1cA1dbWqqKiQvX19Xr77bfV1dWlOXPmKBqNxoxbtmyZjhw50rutXr06oU0DAAY/r4sQtm3bFnN748aNys3N1e7duzVz5sze+4cPH678/PzEdAgAGJIu6DWgcDgsScrJyYm5/+WXX9bIkSM1adIkVVVV6fjx42d9js7OTkUikZgNADD0xX0Zdk9Pj1auXKkZM2Zo0qRJvfcvWrRIY8eOVWFhofbt26fHHntMDQ0NeuONN/p8nurqaj399NPxtgEAGKTiDqCKigrt379f77//fsz9y5cv7/168uTJKigo0OzZs3Xw4EGNHz/+jOepqqpSZWVl7+1IJKKioqJ42wIADBJxBdCKFSv01ltvaceOHRo9evQ5x5aUlEiSGhsb+wygYDCoYDAYTxsAgEHMK4Ccc3rggQe0efNmbd++XcXFxV9bs3fvXklSQUFBXA0CAIYmrwCqqKjQpk2btHXrVmVlZamlpUWSFAqFNGzYMB08eFCbNm3SLbfcossuu0z79u3TQw89pJkzZ2rKlClJ+QcAAAYnrwBav369pFNvNv1fGzZs0JIlS5SRkaF33nlHzz77rKLRqIqKirRw4UI9/vjjCWsYADA0eP8J7lyKiopUW1t7QQ0BAC4OrIaNfhUIBLxruru7vWva2tq8a6T4VrZ+8MEH+2U/wFDDYqQAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMBNzXLXHdzyKRiEKhkNLS0rwWruzq6kpiV0iUeBYjDYVC/VIjSZ2dnd41ra2t3jUD7NsOOKfMzEyv8c45RaNRhcNhZWdnn3UcZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMJFm3cBXnV4ji7WyhqZ4/l/jqenp6fGuibeOYxVDne8xfr4/xwdcAHV0dEiSuru7jTvBQBEOh/ulBkDfotFoXHUdHR3nXBh4wK2G3dPTo8OHDysrK+uMlZMjkYiKiorU3Nx8zhVWhzrm4RTm4RTm4RTm4ZSBMA/OOXV0dKiwsFApKWd/pWfAnQGlpKRo9OjR5xyTnZ19UR9gpzEPpzAPpzAPpzAPp1jPw/l8JAoXIQAATBBAAAATgyqAgsGgVq1apWAwaN2KKebhFObhFObhFObhlME0DwPuIgQAwMVhUJ0BAQCGDgIIAGCCAAIAmCCAAAAmBk0ArVu3TldccYUuueQSlZSU6K9//at1S/3uqaeeUiAQiNkmTpxo3VbS7dixQ7feeqsKCwsVCAS0ZcuWmMedc3ryySdVUFCgYcOGqaysTAcOHLBpNom+bh6WLFlyxvExb948m2aTpLq6Wtdff72ysrKUm5urBQsWqKGhIWbMiRMnVFFRocsuu0yZmZlauHChWltbjTpOjvOZh1mzZp1xPNx7771GHfdtUATQa6+9psrKSq1atUoffvihpk6dqrlz5+ro0aPWrfW7a6+9VkeOHOnd3n//feuWki4ajWrq1Klat25dn4+vXr1aa9eu1fPPP6+dO3fq0ksv1dy5c3XixIl+7jS5vm4eJGnevHkxx8crr7zSjx0mX21trSoqKlRfX6+3335bXV1dmjNnTsxaZQ899JDefPNNvf7666qtrdXhw4d1++23G3adeOczD5K0bNmymONh9erVRh2fhRsEpk+f7ioqKnpvd3d3u8LCQlddXW3YVf9btWqVmzp1qnUbpiS5zZs3997u6elx+fn57plnnum9r7293QWDQffKK68YdNg/vjoPzjm3ePFiN3/+fJN+rBw9etRJcrW1tc65U//36enp7vXXX+8d8/HHHztJrq6uzqrNpPvqPDjn3E033eQefPBBu6bOw4A/Azp58qR2796tsrKy3vtSUlJUVlamuro6w85sHDhwQIWFhRo3bpzuvvtuHTp0yLolU01NTWppaYk5PkKhkEpKSi7K42P79u3Kzc3V1Vdfrfvuu09tbW3WLSXV6VXPc3JyJEm7d+9WV1dXzPEwceJEjRkzZkgfD1+dh9NefvlljRw5UpMmTVJVVZWOHz9u0d5ZDbjFSL/q888/V3d3t/Ly8mLuz8vL0yeffGLUlY2SkhJt3LhRV199tY4cOaKnn35aN954o/bv36+srCzr9ky0tLRIUp/Hx+nHLhbz5s3T7bffruLiYh08eFA/+tGPVF5errq6OqWmplq3l3A9PT1auXKlZsyYoUmTJkk6dTxkZGRoxIgRMWOH8vHQ1zxI0qJFizR27FgVFhZq3759euyxx9TQ0KA33njDsNtYAz6A8F/l5eW9X0+ZMkUlJSUaO3asfve732np0qWGnWEguPPOO3u/njx5sqZMmaLx48dr+/btmj17tmFnyVFRUaH9+/dfFK+DnsvZ5mH58uW9X0+ePFkFBQWaPXu2Dh48qPHjx/d3m30a8H+CGzlypFJTU8+4iqW1tVX5+flGXQ0MI0aM0FVXXaXGxkbrVsycPgY4Ps40btw4jRw5ckgeHytWrNBbb72l9957L+bjW/Lz83Xy5Em1t7fHjB+qx8PZ5qEvJSUlkjSgjocBH0AZGRmaNm2aampqeu/r6elRTU2NSktLDTuzd+zYMR08eFAFBQXWrZgpLi5Wfn5+zPERiUS0c+fOi/74+Oyzz9TW1jakjg/nnFasWKHNmzfr3XffVXFxcczj06ZNU3p6eszx0NDQoEOHDg2p4+Hr5qEve/fulaSBdTxYXwVxPl599VUXDAbdxo0b3UcffeSWL1/uRowY4VpaWqxb61cPP/yw2759u2tqanJ/+ctfXFlZmRs5cqQ7evSodWtJ1dHR4fbs2eP27NnjJLk1a9a4PXv2uE8//dQ559zPf/5zN2LECLd161a3b98+N3/+fFdcXOy++OIL484T61zz0NHR4R555BFXV1fnmpqa3DvvvOO+853vuAkTJrgTJ05Yt54w9913nwuFQm779u3uyJEjvdvx48d7x9x7771uzJgx7t1333W7du1ypaWlrrS01LDrxPu6eWhsbHQ/+clP3K5du1xTU5PbunWrGzdunJs5c6Zx57EGRQA559xzzz3nxowZ4zIyMtz06dNdfX29dUv97o477nAFBQUuIyPDXX755e6OO+5wjY2N1m0l3XvvvecknbEtXrzYOXfqUuwnnnjC5eXluWAw6GbPnu0aGhpsm06Cc83D8ePH3Zw5c9yoUaNcenq6Gzt2rFu2bNmQ+yWtr3+/JLdhw4beMV988YW7//773Te+8Q03fPhwd9ttt7kjR47YNZ0EXzcPhw4dcjNnznQ5OTkuGAy6K6+80v3whz904XDYtvGv4OMYAAAmBvxrQACAoYkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJ/wfJz1pzTS/i/gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tvm.contrib.download import download_testdata\n",
    "\n",
    "# This is clearly not a MNIST image, but whatever\n",
    "#img_url = \"https://www.researchgate.net/publication/321174607/figure/fig3/AS:806993333850113@1569413612260/Example-of-a-MNIST-input-An-image-is-passed-to-the-network-as-a-matrix-of-28-by-28.png\"\n",
    "#img_path = download_testdata(img_url, \"mnist.png\", module=\"data\")\n",
    "img = Image.open(\"seven.png\").resize((28, 28)) #.resize((416, 416))\n",
    "plt.imshow(img)\n",
    "img_ycbcr = img.convert(\"YCbCr\")  # convert to YCbCr\n",
    "img_y, img_cb, img_cr = img_ycbcr.split()\n",
    "x = np.array(img_y)[np.newaxis, np.newaxis, :, :]\n",
    "tvm_x = tvm.nd.array(x.astype(\"float32\"), device=tvm.cpu())\n",
    "print(vm[\"main\"](tvm_x, *params).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = tvm.tir.Schedule(MNIST)\n",
    "\n",
    "conv = sch.get_block(\"conv\", func_name=\"Conv2DRelu_1\")\n",
    "k, i, j, di, dj = sch.get_loops(conv)\n",
    "\n",
    "#sch.reorder(k, i, j, di, dj)\n",
    "\n",
    "sch.parallel(k)\n",
    "sch.unroll(di)\n",
    "sch.vectorize(dj)\n",
    "\n",
    "\n",
    "conv2 = sch.get_block(\"conv\", func_name=\"Conv2DRelu_2\")\n",
    "k, i, j, q, di, dj = sch.get_loops(conv2)\n",
    "\n",
    "sch.reorder(q, k, i, j, di, dj)\n",
    "\n",
    "sch.parallel(q)\n",
    "sch.unroll(di)\n",
    "sch.vectorize(dj)\n",
    "\n",
    "\n",
    "matmul = sch.get_block(\"mul\", func_name=\"Dense\")\n",
    "i, k1, k2, k3 = sch.get_loops(matmul)\n",
    "sch.reorder(k1,i, k2, k3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                          Duration (us)  Percent  Device  Count                                                                   Argument Shapes  \n",
       "Conv2DRelu_2                         333,00    66.82    cpu0      1  float32[8, 14, 14], float32[16, 8, 5, 5], float32[16, 1, 1], float32[16, 14, 14]  \n",
       "Conv2DRelu_1                          10,81     2.17    cpu0      1        float32[28, 28], float32[8, 1, 5, 5], float32[8, 1, 1], float32[8, 28, 28]  \n",
       "Dense                                  5,39     1.08    cpu0      1                  float32[16, 4, 4], float32[10, 256], float32[1, 10], float32[10]  \n",
       "MaxPooling2D_1                         4,35     0.87    cpu0      1                                            float32[8, 28, 28], float32[8, 14, 14]  \n",
       "vm.builtin.check_tensor_info           2,10     0.42    cpu0      1                                                             float32[1, 1, 28, 28]  \n",
       "div255                                 1,66     0.33    cpu0      1                                            float32[1, 1, 28, 28], float32[28, 28]  \n",
       "vm.builtin.check_tensor_info           1,66     0.33    cpu0      1                                                                  float32[8, 1, 1]  \n",
       "MaxPooling2D_2                         1,21     0.24    cpu0      1                                            float32[16, 14, 14], float32[16, 4, 4]  \n",
       "vm.builtin.match_shape                 1,21     0.24    cpu0      1                                                             float32[1, 1, 28, 28]  \n",
       "vm.builtin.match_shape                 1,17     0.24    cpu0      1                                                               float32[8, 1, 5, 5]  \n",
       "vm.builtin.match_shape                 1,10     0.22    cpu0      1                                                              float32[16, 8, 5, 5]  \n",
       "vm.builtin.match_shape                 1,05     0.21    cpu0      1                                                                 float32[16, 1, 1]  \n",
       "vm.builtin.match_shape                 1,02     0.21    cpu0      1                                                                  float32[8, 1, 1]  \n",
       "vm.builtin.check_tensor_info           0,98     0.20    cpu0      1                                                               float32[8, 1, 5, 5]  \n",
       "vm.builtin.match_shape                 0,92     0.18    cpu0      1                                                                  float32[10, 256]  \n",
       "vm.builtin.match_shape                 0,89     0.18    cpu0      1                                                                    float32[1, 10]  \n",
       "vm.builtin.check_tensor_info           0,76     0.15    cpu0      1                                                              float32[16, 8, 5, 5]  \n",
       "vm.builtin.check_tensor_info           0,74     0.15    cpu0      1                                                                    float32[1, 10]  \n",
       "vm.builtin.check_tensor_info           0,74     0.15    cpu0      1                                                                  float32[10, 256]  \n",
       "vm.builtin.check_tensor_info           0,73     0.15    cpu0      1                                                                 float32[16, 1, 1]  \n",
       "----------                                                                                                                                             \n",
       "Sum                                  371,53    74.55             20                                                                                    \n",
       "Total                                498,35             cpu0      1                                                                                    \n",
       "\n",
       "Configuration\n",
       "-------------\n",
       "Number of threads: 2\n",
       "Executor: VM"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = relax.build(MNIST, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu(), profile=True)\n",
    "evaluator = vm.profile(\"main\",\n",
    "    tvm_x, *params\n",
    ")\n",
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                          Duration (us)  Percent  Device  Count                                                                   Argument Shapes  \n",
       "Conv2DRelu_2                         327,32    66.34    cpu0      1  float32[8, 14, 14], float32[16, 8, 5, 5], float32[16, 1, 1], float32[16, 14, 14]  \n",
       "Conv2DRelu_1                          15,20     3.08    cpu0      1        float32[28, 28], float32[8, 1, 5, 5], float32[8, 1, 1], float32[8, 28, 28]  \n",
       "MaxPooling2D_1                         4,69     0.95    cpu0      1                                            float32[8, 28, 28], float32[8, 14, 14]  \n",
       "Dense                                  3,85     0.78    cpu0      1                  float32[16, 4, 4], float32[10, 256], float32[1, 10], float32[10]  \n",
       "vm.builtin.check_tensor_info           2,13     0.43    cpu0      1                                                             float32[1, 1, 28, 28]  \n",
       "vm.builtin.check_tensor_info           1,62     0.33    cpu0      1                                                                  float32[8, 1, 1]  \n",
       "div255                                 1,48     0.30    cpu0      1                                            float32[1, 1, 28, 28], float32[28, 28]  \n",
       "vm.builtin.match_shape                 1,21     0.25    cpu0      1                                                             float32[1, 1, 28, 28]  \n",
       "vm.builtin.match_shape                 1,16     0.23    cpu0      1                                                               float32[8, 1, 5, 5]  \n",
       "MaxPooling2D_2                         1,14     0.23    cpu0      1                                            float32[16, 14, 14], float32[16, 4, 4]  \n",
       "vm.builtin.match_shape                 1,08     0.22    cpu0      1                                                              float32[16, 8, 5, 5]  \n",
       "vm.builtin.match_shape                 1,07     0.22    cpu0      1                                                                 float32[16, 1, 1]  \n",
       "vm.builtin.match_shape                 1,00     0.20    cpu0      1                                                                  float32[8, 1, 1]  \n",
       "vm.builtin.check_tensor_info           0,94     0.19    cpu0      1                                                               float32[8, 1, 5, 5]  \n",
       "vm.builtin.match_shape                 0,91     0.18    cpu0      1                                                                  float32[10, 256]  \n",
       "vm.builtin.match_shape                 0,90     0.18    cpu0      1                                                                    float32[1, 10]  \n",
       "vm.builtin.check_tensor_info           0,80     0.16    cpu0      1                                                              float32[16, 8, 5, 5]  \n",
       "vm.builtin.check_tensor_info           0,71     0.14    cpu0      1                                                                 float32[16, 1, 1]  \n",
       "vm.builtin.check_tensor_info           0,71     0.14    cpu0      1                                                                  float32[10, 256]  \n",
       "vm.builtin.check_tensor_info           0,71     0.14    cpu0      1                                                                    float32[1, 10]  \n",
       "----------                                                                                                                                             \n",
       "Sum                                  368,63    74.71             20                                                                                    \n",
       "Total                                493,43             cpu0      1                                                                                    \n",
       "\n",
       "Configuration\n",
       "-------------\n",
       "Number of threads: 2\n",
       "Executor: VM"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = relax.build(sch.mod, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu(), profile=True)\n",
    "evaluator = vm.profile(\"main\",\n",
    "    tvm_x, *params\n",
    ")\n",
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkResult(min=0.000361029927756654, mean=0.000361029927756654, median=0.000361029927756654, max=0.000361029927756654, std=0.0, results=(0.000361029927756654,))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = relax.build(sch.mod, target=\"llvm\", pipeline=\"default_build\")  # You can try 'default_build'\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu(), profile=False)\n",
    "evaluator = vm.time_evaluator(\"main\", dev=tvm.cpu(), min_repeat_ms=200)(\n",
    "    tvm_x, *params\n",
    ")\n",
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkResult(min=0.0003697487570694087, mean=0.0003697487570694087, median=0.0003697487570694087, max=0.0003697487570694087, std=0.0, results=(0.0003697487570694087,))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = relax.build(MNIST, target=\"llvm\", pipeline=\"default_build\")  # You can try 'default_build'\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu(), profile=False)\n",
    "evaluator = vm.time_evaluator(\"main\", dev=tvm.cpu(), min_repeat_ms=200)(\n",
    "    tvm_x, *params\n",
    ")\n",
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #A2F\">@I</span><span style=\"color: #A2F; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #00F; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #A2F\">@T</span><span style=\"color: #A2F; font-weight: bold\">.</span>prim_func(private<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">flatten</span>(lv5: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">16</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">256</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #A2F; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">256</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i, v_j <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i, j])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(lv5[v_i, v_j <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">256</span>) <span style=\"color: #A2F; font-weight: bold\">//</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">16</span>), v_j <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">16</span>) <span style=\"color: #A2F; font-weight: bold\">//</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>), v_j <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>)])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(compute[v_i, v_j])\n",
       "                compute[v_i, v_j] <span style=\"color: #A2F; font-weight: bold\">=</span> lv5[v_i, v_j <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">256</span>) <span style=\"color: #A2F; font-weight: bold\">//</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">16</span>), v_j <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">16</span>) <span style=\"color: #A2F; font-weight: bold\">//</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>), v_j <span style=\"color: #A2F; font-weight: bold\">%</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>)]\n",
       "\n",
       "    <span style=\"color: #A2F\">@T</span><span style=\"color: #A2F; font-weight: bold\">.</span>prim_func(private<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">max_pool2d</span>(relu: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">28</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">28</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), pool_max: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">14</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">14</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #A2F; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1, ax2, ax3, rv0, rv1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">8</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">14</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">14</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;pool_max&quot;</span>):\n",
       "                v_ax0, v_ax1, v_ax2, v_ax3, v_rv0, v_rv1 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSSRR&quot;</span>, [ax0, ax1, ax2, ax3, rv0, rv1])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(relu[v_ax0, v_ax1, v_ax2 <span style=\"color: #A2F; font-weight: bold\">*</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #A2F; font-weight: bold\">+</span> v_rv0, v_ax3 <span style=\"color: #A2F; font-weight: bold\">*</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #A2F; font-weight: bold\">+</span> v_rv1])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;schedule_rule&quot;</span>: <span style=\"color: #BA2121\">&quot;meta_schedule.pool_max&quot;</span>})\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>init():\n",
       "                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>float32(<span style=\"color: #A2F; font-weight: bold\">-</span><span style=\"color: #008000\">340282346638528859811704183484516925440.0</span>)\n",
       "                pool_max[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3], relu[v_ax0, v_ax1, v_ax2 <span style=\"color: #A2F; font-weight: bold\">*</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #A2F; font-weight: bold\">+</span> v_rv0, v_ax3 <span style=\"color: #A2F; font-weight: bold\">*</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">2</span>) <span style=\"color: #A2F; font-weight: bold\">+</span> v_rv1])\n",
       "\n",
       "    <span style=\"color: #A2F\">@T</span><span style=\"color: #A2F; font-weight: bold\">.</span>prim_func(private<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">max_pool2d1</span>(relu1: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">16</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">14</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">14</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), pool_max: T<span style=\"color: #A2F; font-weight: bold\">.</span>Buffer((T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">16</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #A2F; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1, ax2, ax3, rv0, rv1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>grid(T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">16</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">4</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>), T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;pool_max&quot;</span>):\n",
       "                v_ax0, v_ax1, v_ax2, v_ax3, v_rv0, v_rv1 <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>axis<span style=\"color: #A2F; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSSRR&quot;</span>, [ax0, ax1, ax2, ax3, rv0, rv1])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>reads(relu1[v_ax0, v_ax1, v_ax2 <span style=\"color: #A2F; font-weight: bold\">*</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>) <span style=\"color: #A2F; font-weight: bold\">+</span> v_rv0, v_ax3 <span style=\"color: #A2F; font-weight: bold\">*</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>) <span style=\"color: #A2F; font-weight: bold\">+</span> v_rv1])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3])\n",
       "                T<span style=\"color: #A2F; font-weight: bold\">.</span>block_attr({<span style=\"color: #BA2121\">&quot;schedule_rule&quot;</span>: <span style=\"color: #BA2121\">&quot;meta_schedule.pool_max&quot;</span>})\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>init():\n",
       "                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>float32(<span style=\"color: #A2F; font-weight: bold\">-</span><span style=\"color: #008000\">340282346638528859811704183484516925440.0</span>)\n",
       "                pool_max[v_ax0, v_ax1, v_ax2, v_ax3] <span style=\"color: #A2F; font-weight: bold\">=</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3], relu1[v_ax0, v_ax1, v_ax2 <span style=\"color: #A2F; font-weight: bold\">*</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>) <span style=\"color: #A2F; font-weight: bold\">+</span> v_rv0, v_ax3 <span style=\"color: #A2F; font-weight: bold\">*</span> T<span style=\"color: #A2F; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">3</span>) <span style=\"color: #A2F; font-weight: bold\">+</span> v_rv1])\n",
       "\n",
       "    <span style=\"color: #A2F\">@R</span><span style=\"color: #A2F; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #00F\">forward</span>(x: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv1_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv1_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">8</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv2_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), conv2_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">16</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), dense_weight: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">256</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), dense_bias: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>,), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #A2F; font-weight: bold\">-&gt;</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #A2F; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;num_input&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        cls <span style=\"color: #A2F; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>dataflow():\n",
       "            divide: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>divide(x, R<span style=\"color: #A2F; font-weight: bold\">.</span>const(<span style=\"color: #008000\">255.0</span>, <span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(divide, conv1_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv1: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>reshape(conv1_bias, R<span style=\"color: #A2F; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv2d: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv, lv1)\n",
       "            relu: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">28</span>, <span style=\"color: #008000\">28</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(conv2d)\n",
       "            lv2 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #A2F; font-weight: bold\">.</span>max_pool2d, (relu,), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv3: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>conv2d(lv2, conv2_weight, strides<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], padding<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], dilation<span style=\"color: #A2F; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, data_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, kernel_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;OIHW&quot;</span>, out_layout<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;NCHW&quot;</span>, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv4: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>reshape(conv2_bias, R<span style=\"color: #A2F; font-weight: bold\">.</span>shape([<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>]))\n",
       "            conv2d1: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(lv3, lv4)\n",
       "            relu1: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>nn<span style=\"color: #A2F; font-weight: bold\">.</span>relu(conv2d1)\n",
       "            lv5 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #A2F; font-weight: bold\">.</span>max_pool2d1, (relu1,), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv6 <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #A2F; font-weight: bold\">.</span>flatten, (lv5,), out_sinfo<span style=\"color: #A2F; font-weight: bold\">=</span>R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">256</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            permute_dims: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>permute_dims(dense_weight, axes<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            matmul: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>matmul(lv6, permute_dims, out_dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            add: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> R<span style=\"color: #A2F; font-weight: bold\">.</span>add(matmul, dense_bias)\n",
       "            gv: R<span style=\"color: #A2F; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #A2F; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #A2F; font-weight: bold\">=</span> add\n",
       "            R<span style=\"color: #A2F; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyRelaxModel(relax.frontend.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRelaxModel, self).__init__()\n",
    "        self.conv1 = relax.frontend.nn.Conv2D(1, 8, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        self.relu1 = relax.frontend.nn.ReLU()\n",
    "        self.conv2 = relax.frontend.nn.Conv2D(8, 16, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        self.relu2 = relax.frontend.nn.ReLU()\n",
    "        self.dense = relax.frontend.nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x/255\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = tvm.relax.frontend.nn.tensor_expr_op(topi.nn.pool2d, \"max_pool2d\", [x, (2,2), (2,2), (1,1), (0,0,0,0), \"max\"])\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = tvm.relax.frontend.nn.tensor_expr_op(topi.nn.pool2d, \"max_pool2d\", [x, (3,3), (3,3), (1,1), (0,0,0,0), \"max\"])\n",
    "        x = tvm.relax.frontend.nn.tensor_expr_op(topi.nn.flatten, \"flatten\", [x])\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (1, 1, 28, 28)\n",
    "mod, params_ = MyRelaxModel().export_tvm({\"forward\": {\"x\": relax.frontend.nn.spec.Tensor(input_shape, \"float32\")}})\n",
    "\n",
    "# Unlike in torch, model parameters are not initialized automatically. Let's create them by hand\n",
    "# We'll need them at profile time\n",
    "model_params_tvm = [tvm.nd.array(np.random.randn(*x[1].shape).astype(np.float32)) for x in params_]\n",
    "model_params_tvm_labels = [x[0] for x in params_]\n",
    "\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mod = relax.transform.LegalizeOps()(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.nd.NDArray shape=(1, 10), cpu(0)>\n",
       "array([[ -1.4030411 ,   0.56343764,   7.8122272 ,   8.211108  ,\n",
       "        -12.606699  ,  -5.151139  , -21.856295  ,  26.215685  ,\n",
       "         -6.422785  ,   3.6129267 ]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = relax.build(mod, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu(), profile=True)\n",
    "vm[\"forward\"](tvm_x, *params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  2: tvm::runtime::relax_vm::VirtualMachineProfiler::GetFunction(tvm::runtime::String const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  1: tvm::runtime::relax_vm::VirtualMachineImpl::GetClosureInternal(tvm::runtime::String const&, bool)\n  0: _ZN3tvm7runtime6deta\n  File \"/home/gael/tvm/src/runtime/relax_vm/vm.cc\", line 616\nValueError: Unknown function: forward",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m ex = relax.build(mod, target=\u001b[33m\"\u001b[39m\u001b[33mllvm\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m vm = relax.VirtualMachine(ex, tvm.cpu(), profile=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m evaluator = \u001b[43mvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtvm_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m evaluator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tvm/python/tvm/runtime/relax_vm.py:507\u001b[39m, in \u001b[36mVirtualMachine.profile\u001b[39m\u001b[34m(self, func_name, *args)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[32m    505\u001b[39m     \u001b[38;5;28mself\u001b[39m._convert(arg, cargs)\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m report_json = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprofile\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Report.from_json(report_json)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tvm/python/tvm/_ffi/_ctypes/packed_func.py:245\u001b[39m, in \u001b[36mPackedFuncBase.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    233\u001b[39m ret_tcode = ctypes.c_int()\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    235\u001b[39m     _LIB.TVMFuncCall(\n\u001b[32m    236\u001b[39m         \u001b[38;5;28mself\u001b[39m.handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m     != \u001b[32m0\u001b[39m\n\u001b[32m    244\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     \u001b[43mraise_last_ffi_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m _ = temp_args\n\u001b[32m    247\u001b[39m _ = args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tvm/python/tvm/_ffi/base.py:481\u001b[39m, in \u001b[36mraise_last_ffi_error\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;66;03m# The exception PyObject may contain a large amount of state,\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# including all stack frames that may be inspected in a later\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[38;5;66;03m# PDB post-mortem.  Therefore, we must make sure to remove the\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# underlying PyObject* from the C++ side after we retrieve it.\u001b[39;00m\n\u001b[32m    479\u001b[39m _LIB.TVMDropLastPythonError()\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m py_err\n",
      "\u001b[31mValueError\u001b[39m: Traceback (most recent call last):\n  2: tvm::runtime::relax_vm::VirtualMachineProfiler::GetFunction(tvm::runtime::String const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  1: tvm::runtime::relax_vm::VirtualMachineImpl::GetClosureInternal(tvm::runtime::String const&, bool)\n  0: _ZN3tvm7runtime6deta\n  File \"/home/gael/tvm/src/runtime/relax_vm/vm.cc\", line 616\nValueError: Unknown function: forward"
     ]
    }
   ],
   "source": [
    "\n",
    "ex = relax.build(mod, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu(), profile=True)\n",
    "evaluator = vm.profile(\"forward\",\n",
    "    tvm_x, *params\n",
    ")\n",
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MetaScheduleTuneTIR() got an unexpected keyword argument 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mod = \u001b[43mrelax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMetaScheduleTuneTIR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./tune_tmp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllvm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_trials_global\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m)\u001b[49m(mod)\n",
      "\u001b[31mTypeError\u001b[39m: MetaScheduleTuneTIR() got an unexpected keyword argument 'target'"
     ]
    }
   ],
   "source": [
    "mod = relax.transform.MetaScheduleTuneTIR(work_dir=\"./tune_tmp\", max_trials_global=64)(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
